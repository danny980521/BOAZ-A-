{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BOAZ 멘멘 결정트리&앙상블.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEuN2CnLd2+9Xqqtz8QKGm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danny980521/BOAZ_Analysis_Mentoring_A/blob/main/BOAZ_%EB%A9%98%EB%A9%98_%EA%B2%B0%EC%A0%95%ED%8A%B8%EB%A6%AC%26%EC%95%99%EC%83%81%EB%B8%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi-69wghypvB"
      },
      "source": [
        "#위스콘신 유방암 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "StcLIsGCwlAh",
        "outputId": "ab7a1c3e-603e-4913-bb3d-4616735fd181"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "data = cancer.data\n",
        "label = cancer.target\n",
        "\n",
        "data_df = pd.DataFrame(data, columns = cancer.feature_names)\n",
        "data_df"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0          17.99         10.38  ...          0.4601                  0.11890\n",
              "1          20.57         17.77  ...          0.2750                  0.08902\n",
              "2          19.69         21.25  ...          0.3613                  0.08758\n",
              "3          11.42         20.38  ...          0.6638                  0.17300\n",
              "4          20.29         14.34  ...          0.2364                  0.07678\n",
              "..           ...           ...  ...             ...                      ...\n",
              "564        21.56         22.39  ...          0.2060                  0.07115\n",
              "565        20.13         28.25  ...          0.2572                  0.06637\n",
              "566        16.60         28.08  ...          0.2218                  0.07820\n",
              "567        20.60         29.33  ...          0.4087                  0.12400\n",
              "568         7.76         24.54  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7MieHBf1byw"
      },
      "source": [
        "#decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUokg0r2joiJ",
        "outputId": "08f9c585-65e3-4585-9688-6a0fa14f1d16"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=123)\n",
        "\n",
        "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.915603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPTIp65o1ftQ"
      },
      "source": [
        "#boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yySImUX01iH_"
      },
      "source": [
        "##adaboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4B8-8hwelg_",
        "outputId": "0bc33c7e-c3ee-4e74-a3d5-dc586f20133b"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(n_estimators=200, random_state=123)\n",
        "\n",
        "scores = cross_val_score(ada_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.975423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Wual6l1kui"
      },
      "source": [
        "##xgboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S19BbARjPnL",
        "outputId": "fe669c80-ab93-4a62-d695-982f1c3c77df"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_clf = XGBClassifier(n_estimators=200, random_state=123)\n",
        "\n",
        "scores = cross_val_score(xgb_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.973638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIi0fI38G45o"
      },
      "source": [
        "##lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC8goazCGw8Y",
        "outputId": "2c18855b-a398-49fe-869d-923045bff7be"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm_clf = LGBMClassifier(n_estimators=300, random_state=123)\n",
        "\n",
        "scores = cross_val_score(lgbm_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.971883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk0xzLjU1qVG"
      },
      "source": [
        "#bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBFZQxe-Z-wP",
        "outputId": "dea7212b-021a-46d3-92b4-17bb6c88f29d"
      },
      "source": [
        "#코드 구동에 약 10초가 소요됩니다.\n",
        "from sklearn.ensemble import BaggingClassifier \n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16, random_state=123), \n",
        "    n_estimators=200, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=123)\n",
        "\n",
        "scores = cross_val_score(bag_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.963111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5fAM7791vvF"
      },
      "source": [
        "##random forest\n",
        "decision tree에 배깅을 적용한 것이 random forest이므로 위의 코드와 성능이 비슷할 것으로 예측된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGhmfiAGkH12",
        "outputId": "9a5a0576-ff86-4204-c9f5-3e6cc68cb1e1"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, max_leaf_nodes=16, n_jobs=-1, random_state=123)\n",
        "\n",
        "scores = cross_val_score(rf_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.959618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC15NXuKlxtX"
      },
      "source": [
        "##배깅 직접 구현\n",
        "배깅의 직접 구현도 어렵지 않다. 하는 김에 소프트보팅 방법도 직접 구현해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeE3jbIUl3xb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = 0.2, random_state = 123)\n",
        "\n",
        "bagging_pred = [] #각 모델들의 레이블 예측\n",
        "bagging_predict_proba = [] #각 모델들의 레이블에 속할 확률 예측\n",
        "bagging_predict_result = [] #test set으로 평가한 각 모델들의 accuracy\n",
        "\n",
        "for _ in range(10):  \n",
        "    # 반복 복원추출과정. 중복을 허용하지 않음으로 인해 페이스팅을 구현하고자 한다면 np.random.choice에서 replace=False로 설정하면 된다. default 값은 True이다.\n",
        "    data_index = [data_index for data_index in range(X_train.shape[0])]\n",
        "    random_data_index = np.random.choice(data_index, X_train.shape[0]) \n",
        "    \n",
        "    # decision tree\n",
        "    bg_X_train = pd.DataFrame(X_train).iloc[random_data_index,]\n",
        "    bg_y_train = pd.DataFrame(y_train).iloc[random_data_index,]\n",
        "    dt_clf.fit(bg_X_train, bg_y_train)\n",
        "\n",
        "    pred = dt_clf.predict(X_test)\n",
        "    bagging_pred.append(dt_clf.predict(X_test))\n",
        "    bagging_predict_proba.append(dt_clf.predict_proba(X_test))\n",
        "    bagging_predict_result.append(accuracy_score(y_test, pred))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvHSsZoumbpf",
        "outputId": "0dde4414-6c6a-454b-8a46-80c4a8c1635f"
      },
      "source": [
        "#모델들 예측 결과\n",
        "bagging_predict_result"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9035087719298246,\n",
              " 0.956140350877193,\n",
              " 0.9473684210526315,\n",
              " 0.9385964912280702,\n",
              " 0.868421052631579,\n",
              " 0.9035087719298246,\n",
              " 0.956140350877193,\n",
              " 0.9210526315789473,\n",
              " 0.9736842105263158,\n",
              " 0.956140350877193]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-QYQpw0qHRk",
        "outputId": "35de86ad-1e6f-475e-8104-8aa51fa5317e"
      },
      "source": [
        "# 최종 결과. 각 모델들의 예측 확률을 소프트 보팅 방법으로 합한 후 대소비교를 통해 최종 레이블을 0 또는 1로 결정해주었다. \n",
        "last_proba = np.zeros_like(bagging_predict_proba[0])\n",
        "for i in range(10) :\n",
        "    last_proba += bagging_predict_proba[i]\n",
        "last_pred = np.zeros_like(bagging_pred[0])\n",
        "for i in range(len(last_proba)) :\n",
        "    last_pred[i] = 0 if last_proba[i][0] >= last_proba[i][1] else 1\n",
        "  \n",
        "print(accuracy_score(y_test, last_pred))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9736842105263158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpJ65rE8IepA"
      },
      "source": [
        "부스팅 모델들에 배깅을 적용할 수는 없을까?\n",
        "##bagged xgboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnI79cbsbsoo",
        "outputId": "de120cd6-42fb-46fd-f67b-c4a977f81c4a"
      },
      "source": [
        "#코드 구동에 약 2분이 소요됩니다.\n",
        "bag_xgb_clf = BaggingClassifier(\n",
        "    XGBClassifier(max_features = \"auto\", n_estimators=200, random_state=123), \n",
        "    n_estimators= 200, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=123)\n",
        "\n",
        "scores = cross_val_score(bag_xgb_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.96662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzy_14IQI5Kg"
      },
      "source": [
        "##bagged lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5HpGYDhaKZu",
        "outputId": "b4b86bd5-5fa1-427a-a1e9-62c8ebeb31ba"
      },
      "source": [
        "#코드 구동에 약 4분이 소요됩니다.\n",
        "bag_lgbm_clf = BaggingClassifier(\n",
        "    LGBMClassifier(max_features = \"auto\", n_estimators=300, random_state=123), \n",
        "    n_estimators= 200, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=123)\n",
        "\n",
        "scores = cross_val_score(bag_lgbm_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.973638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvm6Scqz15i7"
      },
      "source": [
        "#voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yqX71dbEc8q"
      },
      "source": [
        "##hard voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eai0yx2j2AWb",
        "outputId": "b625f37b-7b07-43fc-e340-a37907245514"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "vo_clf1 = VotingClassifier(estimators = [('ada',ada_clf), ('xgb',xgb_clf)], voting = 'hard')\n",
        "\n",
        "scores = cross_val_score(vo_clf1, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.975408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htJ7-PTGEe1M"
      },
      "source": [
        "##soft voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZK6WJwKEZOo",
        "outputId": "be298ef5-074a-4207-cd4c-cdfcbda38c10"
      },
      "source": [
        "vo_clf2 = VotingClassifier(estimators = [('ada',ada_clf), ('xgb',xgb_clf)], voting = 'soft')\n",
        "\n",
        "scores = cross_val_score(vo_clf2, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.973638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_TEFN-8GEWl"
      },
      "source": [
        "사이킷런은 weighted average를 활용한 soft voting 또한 지원한다. 보통 점수가 더 잘 나오는 쪽에 가중치를 크게 주면 높은 점수를 기대할 수 있다. 그러나 cv셋에 따라 오버피팅의 가능성이 있으니 주의하자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSyRRkCYF8YA",
        "outputId": "a3d20c18-f8ba-412f-df83-8fe5811fffd3"
      },
      "source": [
        "vo_clf3 = VotingClassifier(estimators = [('ada',ada_clf), ('xgb',xgb_clf)], voting = 'soft', weights = [0.7, 0.3])\n",
        "\n",
        "scores = cross_val_score(vo_clf3, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.975392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co7fdt4RFOu9"
      },
      "source": [
        "분류기간의 성능 차이가 크면 아래처럼 좋은 앙상블 결과를 기대하기 힘들다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua8gbVm2FEne",
        "outputId": "551d4677-6e55-4a8e-ae01-210e69ace2aa"
      },
      "source": [
        "vo_clf4 = VotingClassifier(estimators = [('tree',dt_clf), ('xgb',xgb_clf)], voting = 'soft')\n",
        "\n",
        "scores = cross_val_score(vo_clf4, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.934995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfWTk0zTHHzr"
      },
      "source": [
        "3개 이상의 분류기의 앙상블도 물론 가능하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNS9njmmHHNW",
        "outputId": "49e6b2fb-5247-4076-9220-b0af99f70ebf"
      },
      "source": [
        "vo_clf5 = VotingClassifier(estimators = [('ada',ada_clf), ('xgb',xgb_clf), ('lgbm', lgbm_clf)], voting = 'hard')\n",
        "\n",
        "scores = cross_val_score(vo_clf5, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.971883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBkINExZ15u1"
      },
      "source": [
        "#stacking\n",
        "핸즈온 머신러닝에서는 사이킷런이 스태킹을 직접 지원하지 않는다고 하지만, 업데이트가 된 것인지 찾아보니 지원하는 모듈이 있었다. 심지어 default로 stratified 5-fold를 이용하여 테스트 셋을 예측한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vlm8qkXN2TO",
        "outputId": "0b045ed4-4fa0-43e9-b4ae-5d5359d45255"
      },
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "st_clf = StackingClassifier(estimators=[('ada',ada_clf), ('xgb',xgb_clf)])\n",
        "\n",
        "scores = cross_val_score(st_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.973638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy0ZiwE4Ohhe"
      },
      "source": [
        "final_estimator를 다른 분류기로 설정할 수 있다. default는 linear regressor이다.\n",
        "그 외에 다양한 튜닝법은 사이킷런 레퍼런스에 자세히 설명되어 있다.\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html?highlight=stacking#sklearn.ensemble.StackingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQTuBv26aKaS",
        "outputId": "7d5b8e47-31e5-412f-c53e-f40a793021db"
      },
      "source": [
        "#코드 구동에 약 1분이 소요됩니다.\n",
        "st_clf = StackingClassifier(estimators=[('ada',ada_clf), ('xgb',xgb_clf), ('rf', rf_clf)], final_estimator=LGBMClassifier())\n",
        "\n",
        "scores = cross_val_score(st_clf, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 6))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cv score :  0.971914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V45CPpZmabQK"
      },
      "source": [
        "##stacking 직접 구현(1)\n",
        "스태킹 직접 구현 또한 어렵지 않으니 해보도록 하자. 파머완 코드를 참고했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRzo0EYQb5QO",
        "outputId": "c2802e45-4ff4-4ad1-9818-b86785ef7a67"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_final = LogisticRegression(C=10, random_state=123)\n",
        "\n",
        "dt_clf.fit(X_train, y_train)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "ada_clf.fit(X_train, y_train)\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "dt_pred = dt_clf.predict(X_test)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "ada_pred = ada_clf.predict(X_test)\n",
        "xgb_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "print('dt 정확도 :',accuracy_score(y_test, dt_pred))\n",
        "print('rf 정확도 :',accuracy_score(y_test, rf_pred))\n",
        "print('ada 정확도 :',accuracy_score(y_test, ada_pred))\n",
        "print('xgb 정확도 :',accuracy_score(y_test, xgb_pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dt 정확도 : 0.9298245614035088\n",
            "rf 정확도 : 0.9912280701754386\n",
            "ada 정확도 : 0.9649122807017544\n",
            "xgb 정확도 : 0.9736842105263158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTLhs6myoRed",
        "outputId": "138606c8-a59d-4eac-8a74-2130d615c0cb"
      },
      "source": [
        "#각 예측값을 하나의 배열에 담는다.\n",
        "stacked_pred = np.array([dt_pred, rf_pred, ada_pred, xgb_pred])\n",
        "print(stacked_pred.shape)\n",
        "\n",
        "# transpose를 이용해 행과 열의 위치를 교환한다.\n",
        "stacked_pred = np.transpose(stacked_pred)\n",
        "print(stacked_pred.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 114)\n",
            "(114, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW9USQ8bo9eh",
        "outputId": "bea6caaf-7fe8-4ed5-9851-aa89d533cdb8"
      },
      "source": [
        "lr_final.fit(stacked_pred, y_test)\n",
        "final_pred = lr_final.predict(stacked_pred)\n",
        "\n",
        "print('최종 메타 모델 정확도 : ',accuracy_score(y_test, final_pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 메타 모델 정확도 :  0.9912280701754386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G39fEBHp1oJ"
      },
      "source": [
        "위의 스태킹 모델은 y_test를 학습했기에 과적합 문제가 발생할 수 있다. (랜덤 시드에 따라 정확도가 1.0이 되기도 한다.)\n",
        "##stacking 직접 구현(2)\n",
        "cv세트 기반의 신뢰할만한 스태킹 모델을 직접 구현하자. 파머완에서는 kfold를 사용했지만 여기서는 stratifiedkfold를 이용해 구현하겠다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EaINrSpq00q"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
        "    # 지정된 n_folds 값으로 KFold 생성\n",
        "    kf = StratifiedKFold(n_splits=n_folds, shuffle=False, random_state=123)\n",
        "    \n",
        "    # 추후 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화\n",
        "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
        "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
        "    print(model.__class__.__name__,' model 시작')\n",
        "    \n",
        "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n, y_train_n)):\n",
        "        # 입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 추출\n",
        "        print('\\t 폴드 세트: ',folder_counter+1,' 시작')\n",
        "        X_tr = X_train_n[train_index]\n",
        "        y_tr = y_train_n[train_index]\n",
        "        X_te = X_train_n[valid_index]\n",
        "        \n",
        "        # 폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행\n",
        "        model.fit(X_tr, y_tr)\n",
        "        # 폴드 세트 내부에서 다시 만들어지 검증 데이터로 기반 모델 예측 후 데이터 저장\n",
        "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
        "        # 입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장\n",
        "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
        "        \n",
        "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성\n",
        "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
        "    \n",
        "    # train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
        "    return train_fold_pred, test_pred_mean"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKi2kmLPuEso",
        "outputId": "f73f7b64-0345-4f48-fd90-12db3ed031f3"
      },
      "source": [
        "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 5)\n",
        "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 5)\n",
        "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 5)\n",
        "xgb_train, xgb_test = get_stacking_base_datasets(xgb_clf, X_train, y_train, X_test, 5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier  model 시작\n",
            "\t 폴드 세트:  1  시작\n",
            "\t 폴드 세트:  2  시작\n",
            "\t 폴드 세트:  3  시작\n",
            "\t 폴드 세트:  4  시작\n",
            "\t 폴드 세트:  5  시작\n",
            "RandomForestClassifier  model 시작\n",
            "\t 폴드 세트:  1  시작\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t 폴드 세트:  2  시작\n",
            "\t 폴드 세트:  3  시작\n",
            "\t 폴드 세트:  4  시작\n",
            "\t 폴드 세트:  5  시작\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier  model 시작\n",
            "\t 폴드 세트:  1  시작\n",
            "\t 폴드 세트:  2  시작\n",
            "\t 폴드 세트:  3  시작\n",
            "\t 폴드 세트:  4  시작\n",
            "\t 폴드 세트:  5  시작\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier  model 시작\n",
            "\t 폴드 세트:  1  시작\n",
            "\t 폴드 세트:  2  시작\n",
            "\t 폴드 세트:  3  시작\n",
            "\t 폴드 세트:  4  시작\n",
            "\t 폴드 세트:  5  시작\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOrruEliwDKi",
        "outputId": "6c3056c0-f045-409a-a632-849d92041a04"
      },
      "source": [
        "Stack_final_X_train = np.concatenate((dt_train, rf_train, ada_train, xgb_train), axis=1)\n",
        "Stack_final_X_test = np.concatenate((dt_test, rf_test, ada_test, xgb_test), axis=1)\n",
        "print('원본 학습 피처 데이터 shape:', X_train.shape, '원본 테스트 피처 shape:',X_test.shape)\n",
        "print('스태킹 학습 피처 데이터 shape:',Stack_final_X_train.shape,\n",
        "     '스태킹 테스트 피처 데이터 shape:',Stack_final_X_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 학습 피처 데이터 shape: (455, 30) 원본 테스트 피처 shape: (114, 30)\n",
            "스태킹 학습 피처 데이터 shape: (455, 4) 스태킹 테스트 피처 데이터 shape: (114, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMrYQqIOwZEj",
        "outputId": "097145d9-4f90-4ca1-c4ea-4f26c547d75e"
      },
      "source": [
        "lr_final.fit(Stack_final_X_train, y_train)\n",
        "stack_final = lr_final.predict(Stack_final_X_test)\n",
        "\n",
        "print('최종 메타 모델의 예측 정확도: ', accuracy_score(y_test, stack_final))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 메타 모델의 예측 정확도:  0.9824561403508771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD5aqwx5kluJ"
      },
      "source": [
        "#과제 : 천하제일 오버피팅 대회\n",
        "데이터는 위스콘신 유방암 데이터이고, 평가지표는 위의 코드들과 같이 같이 stratified 5-fold cv score입니다. 점수를 위해서라면 어떤 코드라도 작성하셔도 됩니다. 여러분의 하이퍼 패러미터 튜닝 / 앙상블 실력을 보여주세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMNIeJNzlXGo"
      },
      "source": [
        "#코드\n",
        "#--------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------\n",
        "#점수 산정만 가능하다면 밑의 두 줄 또한 얼마든지 바꾸셔도 됩니다.\n",
        "scores = cross_val_score(당신의 분류기, data, label, scoring = 'accuracy', cv = 5)\n",
        "print('cv score : ', np.round(np.mean(scores), 8))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}