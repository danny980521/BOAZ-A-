{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic regression 구현 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYprx77KiYepok0bOvd93A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danny980521/BOAZ_Analysis_Mentoring_A/blob/main/Logistic_regression_%EA%B5%AC%ED%98%84_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXDUZkIUUtDB"
      },
      "source": [
        "과제 : Logistic regression과 Softmax Regression 함수 중 하나를 골라 Pure Python으로 구현하기(Sklearn, Tensorflow, Pytorch 쓰지 않고 정 안 되면 numpy까지는 사용 가능)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmCAx06Krj6J"
      },
      "source": [
        "#Logistic regression을 구현해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiBia54cUsHb"
      },
      "source": [
        "import numpy as np\n",
        "#데이터는 멘토님이 예시로 드신 데이터를 활용하겠습니다.\n",
        "x_data = np.array([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]])\n",
        "y_data = np.array([0,0,0,1,1,1]).reshape(6,1)\n",
        "#x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "#y_data = [[0], [0], [0], [1], [1], [1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkMUqs_kr4qO",
        "outputId": "5f5199f8-8705-491e-b58a-74908c959af6"
      },
      "source": [
        "#임의의 직선 z = w1x1 + w2x2 + b를 정의합니다.\n",
        "w=np.random.rand(2,1)\n",
        "b=np.random.rand(1)\n",
        "print('w=',w,' w.shape=',w.shape,' b=', b,' b.shape=',b.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w= [[0.14913554]\n",
            " [0.48696511]]  w.shape= (2, 1)  b= [0.12125307]  b.shape= (1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAev7eV5v7MN"
      },
      "source": [
        "#손실함수를 정의합니다.\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "    \n",
        "def loss_func(x, t):\n",
        "    delta = 1e-7\n",
        "    z=np.dot(x, w)+b\n",
        "    y=sigmoid(z)\n",
        "    \n",
        "    return -np.sum(t*np.log(y+delta)+(1-t)*np.log((1-y)+delta))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh5HWsxhwHrb"
      },
      "source": [
        "#수치 미분을 정의합니다.\n",
        "def numerical_derivative(f, x):\n",
        "    delta_x = 1e-4 #매우 작은 값\n",
        "    grad = np.zeros_like(x) #수치미분된 값을 저장할 ndarray\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    \n",
        "    while not it.finished:\n",
        "        idx=it.multi_index\n",
        "        \n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + delta_x\n",
        "        fx1 = f(x)\n",
        "        \n",
        "        x[idx] = tmp_val - delta_x\n",
        "        fx2 = f(x)\n",
        "        \n",
        "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val\n",
        "        it.iternext()\n",
        "        \n",
        "    return grad\n",
        "\n",
        "#예측함수를 정의합니다.\n",
        "def predict(x):\n",
        "    z = np.dot(x,w) + b\n",
        "    y = sigmoid(z)\n",
        "    \n",
        "    if y > 0.5: #0.5를 초과하면 1로 True, 이하면 0으로 False\n",
        "        result = 1\n",
        "    else:\n",
        "        result = 0\n",
        "        \n",
        "    return y, result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne_fQklWwQdP",
        "outputId": "b2fc7db1-ca1d-483c-83d3-1932c5ddfe92"
      },
      "source": [
        "#학습\n",
        "learning_rate = 1e-2\n",
        "\n",
        "f = lambda x : loss_func(x_data, y_data)\n",
        "\n",
        "print(\"initial error value=\", loss_func(x_data, y_data), \"\\ninitial w=\", w, \"\\nb=\",b)\n",
        "\n",
        "for step in range(50001):\n",
        "    w -= learning_rate *numerical_derivative(f,w)\n",
        "    b -= learning_rate *numerical_derivative(f,b)\n",
        "    if(step%400==0):\n",
        "        print(\"step =\",step,\"error value=\", loss_func(x_data, y_data),\"w=\",w,\"b=\",b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial error value= 5.202514715242072 \n",
            "initial w= [[0.14913554]\n",
            " [0.48696511]] \n",
            "b= [0.12125307]\n",
            "step = 0 error value= 4.914327293691964 w= [[0.1174885 ]\n",
            " [0.44611142]] b= [0.10202691]\n",
            "step = 400 error value= 1.9579227077013939 w= [[ 0.98159242]\n",
            " [-0.37801133]] b= [-2.12460617]\n",
            "step = 800 error value= 1.4227404393693788 w= [[ 1.16717141]\n",
            " [-0.0720927 ]] b= [-3.54415346]\n",
            "step = 1200 error value= 1.1071975652328512 w= [[1.32433543]\n",
            " [0.1479622 ]] b= [-4.63577747]\n",
            "step = 1600 error value= 0.9045879709639213 w= [[1.46419819]\n",
            " [0.30729763]] b= [-5.51195631]\n",
            "step = 2000 error value= 0.7648284311485106 w= [[1.58833528]\n",
            " [0.42986227]] b= [-6.24016328]\n",
            "step = 2400 error value= 0.6629378235770206 w= [[1.69914744]\n",
            " [0.52867658]] b= [-6.86207414]\n",
            "step = 2800 error value= 0.5854323090357306 w= [[1.79891356]\n",
            " [0.61113567]] b= [-7.40448771]\n",
            "step = 3200 error value= 0.5244924848011457 w= [[1.88951332]\n",
            " [0.68174082]] b= [-7.88541003]\n",
            "step = 3600 error value= 0.47530183844870066 w= [[1.97243974]\n",
            " [0.74340167]] b= [-8.31743275]\n",
            "step = 4000 error value= 0.434741567964076 w= [[2.04887248]\n",
            " [0.79809403]] b= [-8.70967058]\n",
            "step = 4400 error value= 0.40070663469704715 w= [[2.11974947]\n",
            " [0.84721483]] b= [-9.06891816]\n",
            "step = 4800 error value= 0.37172600547789947 w= [[2.18582423]\n",
            " [0.89178508]] b= [-9.40036907]\n",
            "step = 5200 error value= 0.34674103261006944 w= [[2.2477091]\n",
            " [0.9325721]] b= [-9.70807914]\n",
            "step = 5600 error value= 0.32497046477880415 w= [[2.30590742]\n",
            " [0.97016625]] b= [-9.99527468]\n",
            "step = 6000 error value= 0.3058251284949308 w= [[2.3608374 ]\n",
            " [1.00503092]] b= [-10.26456373]\n",
            "step = 6400 error value= 0.2888522423260018 w= [[2.41285005]\n",
            " [1.03753622]] b= [-10.51808427]\n",
            "step = 6800 error value= 0.27369803520893415 w= [[2.46224267]\n",
            " [1.06798221]] b= [-10.75761081]\n",
            "step = 7200 error value= 0.2600820226609547 w= [[2.50926924]\n",
            " [1.09661545]] b= [-10.98463234]\n",
            "step = 7600 error value= 0.24777891200763283 w= [[2.5541484 ]\n",
            " [1.12364088]] b= [-11.20041063]\n",
            "step = 8000 error value= 0.2366056221390648 w= [[2.5970697 ]\n",
            " [1.14923068]] b= [-11.40602426]\n",
            "step = 8400 error value= 0.22641180703347916 w= [[2.63819853]\n",
            " [1.17353081]] b= [-11.60240252]\n",
            "step = 8800 error value= 0.21707282676084624 w= [[2.67768007]\n",
            " [1.19666611]] b= [-11.79035191]\n",
            "step = 9200 error value= 0.20848445848370456 w= [[2.71564245]\n",
            " [1.21874412]] b= [-11.97057682]\n",
            "step = 9600 error value= 0.20055886442025794 w= [[2.75219935]\n",
            " [1.23985815]] b= [-12.14369624]\n",
            "step = 10000 error value= 0.19322148116824714 w= [[2.78745204]\n",
            " [1.26008969]] b= [-12.310257]\n",
            "step = 10400 error value= 0.18640859346859928 w= [[2.82149119]\n",
            " [1.27951028]] b= [-12.47074465]\n",
            "step = 10800 error value= 0.18006542268473663 w= [[2.85439828]\n",
            " [1.29818311]] b= [-12.62559232]\n",
            "step = 11200 error value= 0.17414460676135893 w= [[2.88624679]\n",
            " [1.31616423]] b= [-12.77518805]\n",
            "step = 11600 error value= 0.16860498106053584 w= [[2.91710324]\n",
            " [1.3335036 ]] b= [-12.91988082]\n",
            "step = 12000 error value= 0.1634105926927059 w= [[2.94702802]\n",
            " [1.35024595]] b= [-13.05998571]\n",
            "step = 12400 error value= 0.15852989769000225 w= [[2.97607617]\n",
            " [1.36643148]] b= [-13.19578813]\n",
            "step = 12800 error value= 0.15393510256417378 w= [[3.00429794]\n",
            " [1.38209642]] b= [-13.32754745]\n",
            "step = 13200 error value= 0.14960162077750705 w= [[3.03173937]\n",
            " [1.39727361]] b= [-13.45550012]\n",
            "step = 13600 error value= 0.14550762134427248 w= [[3.05844272]\n",
            " [1.41199282]] b= [-13.57986227]\n",
            "step = 14000 error value= 0.14163365180718496 w= [[3.08444692]\n",
            " [1.42628118]] b= [-13.700832]\n",
            "step = 14400 error value= 0.1379623216447885 w= [[3.10978786]\n",
            " [1.44016348]] b= [-13.81859135]\n",
            "step = 14800 error value= 0.13447803507981243 w= [[3.13449874]\n",
            " [1.45366242]] b= [-13.93330798]\n",
            "step = 15200 error value= 0.1311667645042839 w= [[3.15861029]\n",
            " [1.46679881]] b= [-14.04513667]\n",
            "step = 15600 error value= 0.1280158574809169 w= [[3.18215106]\n",
            " [1.47959184]] b= [-14.1542206]\n",
            "step = 16000 error value= 0.12501387164332303 w= [[3.20514759]\n",
            " [1.49205918]] b= [-14.26069249]\n",
            "step = 16400 error value= 0.12215043289073636 w= [[3.2276246 ]\n",
            " [1.50421718]] b= [-14.3646756]\n",
            "step = 16800 error value= 0.11941611312265284 w= [[3.24960517]\n",
            " [1.51608098]] b= [-14.4662846]\n",
            "step = 17200 error value= 0.11680232443604584 w= [[3.27111085]\n",
            " [1.52766463]] b= [-14.56562639]\n",
            "step = 17600 error value= 0.11430122725031049 w= [[3.29216182]\n",
            " [1.53898118]] b= [-14.66280075]\n",
            "step = 18000 error value= 0.11190565026243365 w= [[3.312777  ]\n",
            " [1.55004281]] b= [-14.75790097]\n",
            "step = 18400 error value= 0.10960902048866504 w= [[3.33297415]\n",
            " [1.56086084]] b= [-14.85101442]\n",
            "step = 18800 error value= 0.10740530193735054 w= [[3.35276994]\n",
            " [1.5714459 ]] b= [-14.94222302]\n",
            "step = 19200 error value= 0.10528894169296878 w= [[3.37218009]\n",
            " [1.58180788]] b= [-15.03160373]\n",
            "step = 19600 error value= 0.10325482238497244 w= [[3.39121939]\n",
            " [1.59195611]] b= [-15.11922886]\n",
            "step = 20000 error value= 0.10129822017454919 w= [[3.4099018 ]\n",
            " [1.60189929]] b= [-15.20516654]\n",
            "step = 20400 error value= 0.09941476752469602 w= [[3.4282405 ]\n",
            " [1.61164562]] b= [-15.28948096]\n",
            "step = 20800 error value= 0.0976004201287108 w= [[3.44624796]\n",
            " [1.62120282]] b= [-15.37223271]\n",
            "step = 21200 error value= 0.09585142746412728 w= [[3.46393597]\n",
            " [1.63057816]] b= [-15.45347902]\n",
            "step = 21600 error value= 0.09416430651573152 w= [[3.4813157 ]\n",
            " [1.63977849]] b= [-15.53327402]\n",
            "step = 22000 error value= 0.09253581827601585 w= [[3.49839775]\n",
            " [1.64881027]] b= [-15.61166898]\n",
            "step = 22400 error value= 0.09096294668591845 w= [[3.51519218]\n",
            " [1.65767963]] b= [-15.68871246]\n",
            "step = 22800 error value= 0.08944287972447855 w= [[3.53170855]\n",
            " [1.66639236]] b= [-15.76445053]\n",
            "step = 23200 error value= 0.0879729923955963 w= [[3.54795593]\n",
            " [1.67495393]] b= [-15.83892695]\n",
            "step = 23600 error value= 0.08655083139291077 w= [[3.56394298]\n",
            " [1.68336955]] b= [-15.91218329]\n",
            "step = 24000 error value= 0.08517410125258225 w= [[3.57967792]\n",
            " [1.69164414]] b= [-15.98425909]\n",
            "step = 24400 error value= 0.08384065182781303 w= [[3.59516861]\n",
            " [1.6997824 ]] b= [-16.055192]\n",
            "step = 24800 error value= 0.0825484669400692 w= [[3.61042254]\n",
            " [1.70778877]] b= [-16.12501788]\n",
            "step = 25200 error value= 0.08129565407971767 w= [[3.62544685]\n",
            " [1.71566751]] b= [-16.19377093]\n",
            "step = 25600 error value= 0.08008043504438812 w= [[3.64024837]\n",
            " [1.72342264]] b= [-16.26148378]\n",
            "step = 26000 error value= 0.07890113741680178 w= [[3.65483363]\n",
            " [1.73105801]] b= [-16.32818758]\n",
            "step = 26400 error value= 0.07775618679535742 w= [[3.66920887]\n",
            " [1.73857729]] b= [-16.39391211]\n",
            "step = 26800 error value= 0.0766440997009336 w= [[3.68338007]\n",
            " [1.74598399]] b= [-16.45868584]\n",
            "step = 27200 error value= 0.07556347709203448 w= [[3.69735294]\n",
            " [1.75328144]] b= [-16.52253599]\n",
            "step = 27600 error value= 0.07451299842828067 w= [[3.71113299]\n",
            " [1.76047286]] b= [-16.58548867]\n",
            "step = 28000 error value= 0.07349141622870373 w= [[3.72472546]\n",
            " [1.76756129]] b= [-16.64756885]\n",
            "step = 28400 error value= 0.07249755107735728 w= [[3.73813541]\n",
            " [1.77454967]] b= [-16.70880049]\n",
            "step = 28800 error value= 0.07153028703388596 w= [[3.75136769]\n",
            " [1.7814408 ]] b= [-16.76920657]\n",
            "step = 29200 error value= 0.07058856741112444 w= [[3.76442694]\n",
            " [1.78823737]] b= [-16.82880915]\n",
            "step = 29600 error value= 0.0696713908859777 w= [[3.77731765]\n",
            " [1.79494195]] b= [-16.8876294]\n",
            "step = 30000 error value= 0.06877780791311164 w= [[3.79004412]\n",
            " [1.80155701]] b= [-16.94568767]\n",
            "step = 30400 error value= 0.06790691741438878 w= [[3.80261049]\n",
            " [1.80808494]] b= [-17.00300353]\n",
            "step = 30800 error value= 0.06705786371952559 w= [[3.81502074]\n",
            " [1.81452801]] b= [-17.0595958]\n",
            "step = 31200 error value= 0.06622983373594778 w= [[3.82727871]\n",
            " [1.82088841]] b= [-17.11548258]\n",
            "step = 31600 error value= 0.06542205432810126 w= [[3.83938811]\n",
            " [1.82716826]] b= [-17.17068131]\n",
            "step = 32000 error value= 0.06463378988827996 w= [[3.85135248]\n",
            " [1.83336956]] b= [-17.22520879]\n",
            "step = 32400 error value= 0.0638643400828248 w= [[3.86317529]\n",
            " [1.83949429]] b= [-17.2790812]\n",
            "step = 32800 error value= 0.06311303775905579 w= [[3.87485983]\n",
            " [1.84554432]] b= [-17.33231415]\n",
            "step = 33200 error value= 0.062379246999770765 w= [[3.88640931]\n",
            " [1.85152145]] b= [-17.38492268]\n",
            "step = 33600 error value= 0.06166236131320642 w= [[3.89782683]\n",
            " [1.85742744]] b= [-17.43692133]\n",
            "step = 34000 error value= 0.060961801947653625 w= [[3.90911536]\n",
            " [1.86326397]] b= [-17.48832412]\n",
            "step = 34400 error value= 0.060277016320745794 w= [[3.9202778 ]\n",
            " [1.86903266]] b= [-17.53914459]\n",
            "step = 34800 error value= 0.05960747655444234 w= [[3.93131693]\n",
            " [1.87473508]] b= [-17.58939582]\n",
            "step = 35200 error value= 0.05895267810748034 w= [[3.94223545]\n",
            " [1.88037274]] b= [-17.63909048]\n",
            "step = 35600 error value= 0.05831213849782173 w= [[3.95303598]\n",
            " [1.8859471 ]] b= [-17.68824079]\n",
            "step = 36000 error value= 0.057685396108202884 w= [[3.96372104]\n",
            " [1.89145958]] b= [-17.73685857]\n",
            "step = 36400 error value= 0.05707200906860705 w= [[3.97429307]\n",
            " [1.89691155]] b= [-17.78495528]\n",
            "step = 36800 error value= 0.056471554209888794 w= [[3.98475445]\n",
            " [1.90230432]] b= [-17.832542]\n",
            "step = 37200 error value= 0.05588362608330607 w= [[3.99510746]\n",
            " [1.90763917]] b= [-17.87962947]\n",
            "step = 37600 error value= 0.05530783604121298 w= [[4.00535435]\n",
            " [1.91291734]] b= [-17.92622807]\n",
            "step = 38000 error value= 0.054743811374443466 w= [[4.01549725]\n",
            " [1.91814002]] b= [-17.97234788]\n",
            "step = 38400 error value= 0.05419119450239091 w= [[4.02553826]\n",
            " [1.92330839]] b= [-18.01799867]\n",
            "step = 38800 error value= 0.05364964221203108 w= [[4.03547942]\n",
            " [1.92842355]] b= [-18.0631899]\n",
            "step = 39200 error value= 0.05311882494247921 w= [[4.04532269]\n",
            " [1.93348661]] b= [-18.10793075]\n",
            "step = 39600 error value= 0.05259842611193115 w= [[4.05506998]\n",
            " [1.93849861]] b= [-18.15223014]\n",
            "step = 40000 error value= 0.05208814148409644 w= [[4.06472314]\n",
            " [1.94346058]] b= [-18.19609672]\n",
            "step = 40400 error value= 0.05158767857139982 w= [[4.07428399]\n",
            " [1.94837351]] b= [-18.23953888]\n",
            "step = 40800 error value= 0.0510967560725389 w= [[4.08375426]\n",
            " [1.95323837]] b= [-18.28256478]\n",
            "step = 41200 error value= 0.05061510334208705 w= [[4.09313567]\n",
            " [1.9580561 ]] b= [-18.32518233]\n",
            "step = 41600 error value= 0.050142459889999526 w= [[4.10242986]\n",
            " [1.96282759]] b= [-18.36739923]\n",
            "step = 42000 error value= 0.049678574909125674 w= [[4.11163845]\n",
            " [1.96755374]] b= [-18.40922296]\n",
            "step = 42400 error value= 0.04922320682887317 w= [[4.120763 ]\n",
            " [1.9722354]] b= [-18.45066079]\n",
            "step = 42800 error value= 0.0487761228933719 w= [[4.12980502]\n",
            " [1.97687341]] b= [-18.49171979]\n",
            "step = 43200 error value= 0.04833709876256976 w= [[4.13876601]\n",
            " [1.98146857]] b= [-18.53240685]\n",
            "step = 43600 error value= 0.04790591813480484 w= [[4.14764739]\n",
            " [1.98602167]] b= [-18.57272866]\n",
            "step = 44000 error value= 0.04748237238956272 w= [[4.15645058]\n",
            " [1.99053348]] b= [-18.61269172]\n",
            "step = 44400 error value= 0.047066260249112535 w= [[4.16517694]\n",
            " [1.99500475]] b= [-18.65230238]\n",
            "step = 44800 error value= 0.046657387457893 w= [[4.1738278 ]\n",
            " [1.99943619]] b= [-18.69156681]\n",
            "step = 45200 error value= 0.046255566478595814 w= [[4.18240446]\n",
            " [2.00382852]] b= [-18.73049102]\n",
            "step = 45600 error value= 0.04586061620388208 w= [[4.19090818]\n",
            " [2.00818241]] b= [-18.76908088]\n",
            "step = 46000 error value= 0.04547236168284354 w= [[4.19934019]\n",
            " [2.01249855]] b= [-18.80734208]\n",
            "step = 46400 error value= 0.04509063386132485 w= [[4.20770169]\n",
            " [2.01677759]] b= [-18.84528019]\n",
            "step = 46800 error value= 0.044715269335306 w= [[4.21599386]\n",
            " [2.02102015]] b= [-18.88290063]\n",
            "step = 47200 error value= 0.04434611011654026 w= [[4.22421783]\n",
            " [2.02522685]] b= [-18.92020869]\n",
            "step = 47600 error value= 0.0439830034098049 w= [[4.23237471]\n",
            " [2.02939831]] b= [-18.95720951]\n",
            "step = 48000 error value= 0.04362580140105033 w= [[4.2404656]\n",
            " [2.0335351]] b= [-18.99390814]\n",
            "step = 48400 error value= 0.04327436105584791 w= [[4.24849155]\n",
            " [2.0376378 ]] b= [-19.03030946]\n",
            "step = 48800 error value= 0.04292854392755005 w= [[4.25645359]\n",
            " [2.04170697]] b= [-19.06641827]\n",
            "step = 49200 error value= 0.04258821597463888 w= [[4.26435275]\n",
            " [2.04574316]] b= [-19.10223925]\n",
            "step = 49600 error value= 0.042253247386723806 w= [[4.27219  ]\n",
            " [2.0497469]] b= [-19.13777694]\n",
            "step = 50000 error value= 0.04192351241874401 w= [[4.27996631]\n",
            " [2.0537187 ]] b= [-19.17303581]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtlLpbqBLNP-",
        "outputId": "58c609d9-22df-475b-fd80-60c1114bbceb"
      },
      "source": [
        "#예측\n",
        "real_val, logical_val = predict([4,4])\n",
        "print(real_val, logical_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.99789578] 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}